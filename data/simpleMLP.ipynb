{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd69627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85956a43",
   "metadata": {},
   "source": [
    "- design a neural network to predict 3d pose from 2d coords\n",
    "- options:\n",
    "\n",
    "1. simple MLP:\n",
    "    - input: single frame with camera views concatenated -> (C, J, 2) \n",
    "    - output: 3d coords (J, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75cb891",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_JOINTS = 20\n",
    "NUM_CAMS = 6\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c19003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c86464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for metrics it needs to be (J, 3)\n",
    "\n",
    "# for a test, run a sequence and network will output (60) length vector for each frame in the sequence\n",
    "# (60) -> (20,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48676951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class SimpleMLP(nn.Module):\n",
    "\n",
    "    def __init__(self, activation_function, dropout=0.5):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features = NUM_JOINTS * NUM_CAMS * 3, out_features = 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(in_features = 1024, out_features = 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(in_features= 1024, out_features= NUM_JOINTS * 3)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Defines a forward pass through the network.\"\"\"\n",
    "        # protect the data and turn all nans to zeros\n",
    "        x[torch.isnan(x)] = 0\n",
    "        # preserve batch dimension, but flatten the rest (C, J, 2) to single vector\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        return self.net(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b3efa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1484860"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f73059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, criterion, loader: DataLoader, device: str):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for dets_2d, gt_3d in loader:\n",
    "            dets_2d = dets_2d.to(device)\n",
    "            gt_3d = gt_3d.to(device)\n",
    "            # flatten the targets before loss computation\n",
    "            gt_3d = gt_3d.view(gt_3d.size(0), -1)\n",
    "\n",
    "            preds = model(dets_2d)  # Forward pass\n",
    "            loss = criterion(preds, gt_3d)  # Compute validation loss\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_loss = val_running_loss / len(loader)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c136069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model ,criterion, optimizer, train_loader, val_loader, device, epochs=20):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"WE ARE IN EPOCH {epoch}\")\n",
    "        # Training phase\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for dets_2d, gt_3d in train_loader:\n",
    "\n",
    "            dets_2d = dets_2d.to(device)\n",
    "            gt_3d = gt_3d.to(device)\n",
    "            # flatten 3d gt to match model output\n",
    "            gt_3d = gt_3d.view(gt_3d.size(0), -1)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "\n",
    "\n",
    "            preds = model(dets_2d)  # Forward pass\n",
    "            loss = criterion(preds, gt_3d)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "\n",
    "            running_loss += loss.item()  # Accumulate batch loss\n",
    "\n",
    "        # Calculate epoch training accuracy\n",
    "        # Validation phase (call separate function)\n",
    "        val_loss = evaluate_model(model, criterion,val_loader,device) #CAUTION: See note above\n",
    "\n",
    "        # Print progress\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}], \"\n",
    "            f\"Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "            f\"Val Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d9e11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE ARE IN EPOCH 0\n",
      "Epoch [1/20], Train Loss: 6.1861, Val Loss: 1.9445\n",
      "WE ARE IN EPOCH 1\n",
      "Epoch [2/20], Train Loss: 2.1264, Val Loss: 2.1107\n",
      "WE ARE IN EPOCH 2\n",
      "Epoch [3/20], Train Loss: 2.0139, Val Loss: 1.8036\n",
      "WE ARE IN EPOCH 3\n",
      "Epoch [4/20], Train Loss: 1.9528, Val Loss: 1.6705\n",
      "WE ARE IN EPOCH 4\n",
      "Epoch [5/20], Train Loss: 1.8839, Val Loss: 2.1080\n",
      "WE ARE IN EPOCH 5\n",
      "Epoch [6/20], Train Loss: 1.9328, Val Loss: 1.7658\n",
      "WE ARE IN EPOCH 6\n",
      "Epoch [7/20], Train Loss: 1.8674, Val Loss: 1.9088\n",
      "WE ARE IN EPOCH 7\n",
      "Epoch [8/20], Train Loss: 1.8464, Val Loss: 1.8857\n",
      "WE ARE IN EPOCH 8\n",
      "Epoch [9/20], Train Loss: 1.8432, Val Loss: 2.0370\n",
      "WE ARE IN EPOCH 9\n",
      "Epoch [10/20], Train Loss: 1.8268, Val Loss: 1.9790\n",
      "WE ARE IN EPOCH 10\n",
      "Epoch [11/20], Train Loss: 1.7842, Val Loss: 2.0294\n",
      "WE ARE IN EPOCH 11\n",
      "Epoch [12/20], Train Loss: 1.8508, Val Loss: 1.7658\n",
      "WE ARE IN EPOCH 12\n",
      "Epoch [13/20], Train Loss: 1.7943, Val Loss: 2.3524\n",
      "WE ARE IN EPOCH 13\n",
      "Epoch [14/20], Train Loss: 1.7643, Val Loss: 1.8465\n",
      "WE ARE IN EPOCH 14\n",
      "Epoch [15/20], Train Loss: 1.7748, Val Loss: 2.1721\n",
      "WE ARE IN EPOCH 15\n",
      "Epoch [16/20], Train Loss: 1.7840, Val Loss: 2.2228\n",
      "WE ARE IN EPOCH 16\n",
      "Epoch [17/20], Train Loss: 1.7254, Val Loss: 1.6598\n",
      "WE ARE IN EPOCH 17\n",
      "Epoch [18/20], Train Loss: 1.7134, Val Loss: 2.0513\n",
      "WE ARE IN EPOCH 18\n",
      "Epoch [19/20], Train Loss: 1.7382, Val Loss: 1.7772\n",
      "WE ARE IN EPOCH 19\n",
      "Epoch [20/20], Train Loss: 1.6723, Val Loss: 1.8748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.874805474473584"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "from data_loader import get_data_loaders\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders()\n",
    "model = SimpleMLP(nn.ReLU()).to(device)\n",
    "optimizer = optim.AdamW(model.parameters())\n",
    "\n",
    "train_model(model, nn.MSELoss(), optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501cb28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
